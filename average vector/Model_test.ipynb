{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_path = \"M:\\MAP\\GoogleNews-vectors-negative300.bin.gz\"\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True,limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc='''\n",
    "It's against nature': illegal wildlife trade casts shadow over traditional Chinese medicine\n",
    "This is not as much a Chinese medicine practitioner issue, it is more the industry, the people who make money,” Lao said.\n",
    "Richard Thomas, communications director at Traffic, said: “The issue is very much within the TCM consciousness.”Facebook Twitter Pinterest Traditional Chinese medicine products are dispensed at a hospital in Shanxi province.\n",
    "Xi is firmly behind the idea of combining traditional Chinese and western medicine, and has encouraged the acceleration of research on TCM drugs.\n",
    "Facebook Twitter Pinterest Traders wait for customers at a traditional Chinese medicine market in Bozhou, Anhui province, China.\n",
    "Moves are also afoot globally to stop all use of endangered wildlife in traditional medicine.\n",
    "'''\n",
    "test_img='''\n",
    "person retro business paper sign money travel vintage commerce old people text art dollar currency card vehicle bill symbol signalise\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(test_doc):\n",
    "    '''--------Basic clean--------'''\n",
    "    test_doc=test_doc.replace(\"\\r\",\" \")\n",
    "    test_doc=test_doc.replace(\"\\n\",\" \")\n",
    "    \n",
    "    # Remove 's\n",
    "    test_doc=test_doc.replace('\"','')\n",
    "    test_doc=test_doc.replace(\"'s\",\"\")\n",
    "    \n",
    "    # To lowercase\n",
    "    test_doc=test_doc.lower()\n",
    "    \n",
    "    # Remove signa\n",
    "    punctuation_signs = list(\"?:!.,;\")\n",
    "\n",
    "    for punct_sign in punctuation_signs:\n",
    "        test_doc = test_doc.replace(punct_sign, '')\n",
    "        \n",
    "    test_doc = test_doc.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    test_doc = test_doc.replace(\"  \",\" \")\n",
    "    \n",
    "    '''--------lemmatize--------'''\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "     # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = test_doc\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    test_doc = \" \".join(lemmatized_list)\n",
    "    \n",
    "    '''--------remove stopwords--------'''\n",
    "    stop_words=list(stopwords.words('english'))\n",
    "\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        test_doc = test_doc.replace(regex_stopword, '')\n",
    "    \n",
    "    return test_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_doc=clean_text(test_doc)\n",
    "clean_img=clean_text(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized_doc = tokenizer.tokenize(clean_doc)\n",
    "tokenized_img = tokenizer.tokenize(clean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "average_vec_doc=get_average_word2vec(tokenized_doc,word2vec)\n",
    "average_vec_img=get_average_word2vec(tokenized_img,word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'avg_vec.mdl'\n",
    "news_clf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARTS</td>\n",
       "      <td>0.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>0.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLACK VOICES</td>\n",
       "      <td>1.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>7.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLLEGE</td>\n",
       "      <td>0.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COMEDY</td>\n",
       "      <td>1.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>0.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CULTURE &amp; ARTS</td>\n",
       "      <td>1.07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIVORCE</td>\n",
       "      <td>0.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>0.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>1.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENVIRONMENT</td>\n",
       "      <td>1.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FIFTY</td>\n",
       "      <td>0.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FOOD &amp; DRINK</td>\n",
       "      <td>1.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GOOD NEWS</td>\n",
       "      <td>0.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GREEN</td>\n",
       "      <td>1.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HEALTHY LIVING</td>\n",
       "      <td>3.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HOME &amp; LIVING</td>\n",
       "      <td>0.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>2.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LATINO VOICES</td>\n",
       "      <td>0.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MEDIA</td>\n",
       "      <td>1.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>0.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>1.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PARENTS</td>\n",
       "      <td>0.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>16.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QUEER VOICES</td>\n",
       "      <td>0.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>1.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>1.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>STYLE</td>\n",
       "      <td>0.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>5.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TASTE</td>\n",
       "      <td>0.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TECH</td>\n",
       "      <td>2.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>4.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>WEDDINGS</td>\n",
       "      <td>0.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>WEIRD NEWS</td>\n",
       "      <td>0.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>15.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>WOMEN</td>\n",
       "      <td>0.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>5.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WORLDPOST</td>\n",
       "      <td>10.85%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Categories  Confidence\n",
       "0             ARTS       0.94%\n",
       "1   ARTS & CULTURE       0.55%\n",
       "2     BLACK VOICES       1.33%\n",
       "3         BUSINESS       7.16%\n",
       "4          COLLEGE       0.46%\n",
       "5           COMEDY       1.61%\n",
       "6            CRIME       0.50%\n",
       "7   CULTURE & ARTS       1.07%\n",
       "8          DIVORCE       0.08%\n",
       "9        EDUCATION       0.40%\n",
       "10   ENTERTAINMENT       1.99%\n",
       "11     ENVIRONMENT       1.88%\n",
       "12           FIFTY       0.21%\n",
       "13    FOOD & DRINK       1.45%\n",
       "14       GOOD NEWS       0.10%\n",
       "15           GREEN       1.36%\n",
       "16  HEALTHY LIVING       3.23%\n",
       "17   HOME & LIVING       0.94%\n",
       "18          IMPACT       2.50%\n",
       "19   LATINO VOICES       0.22%\n",
       "20           MEDIA       1.42%\n",
       "21           MONEY       0.99%\n",
       "22       PARENTING       1.67%\n",
       "23         PARENTS       0.14%\n",
       "24        POLITICS      16.80%\n",
       "25    QUEER VOICES       0.39%\n",
       "26        RELIGION       1.31%\n",
       "27         SCIENCE       1.92%\n",
       "28          SPORTS       1.31%\n",
       "29           STYLE       0.33%\n",
       "30  STYLE & BEAUTY       5.29%\n",
       "31           TASTE       0.50%\n",
       "32            TECH       2.66%\n",
       "33          TRAVEL       4.22%\n",
       "34        WEDDINGS       0.21%\n",
       "35      WEIRD NEWS       0.42%\n",
       "36        WELLNESS      15.67%\n",
       "37           WOMEN       0.38%\n",
       "38      WORLD NEWS       5.54%\n",
       "39       WORLDPOST      10.85%"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_doc=news_clf.predict_proba([average_vec_doc])\n",
    "confidence_img=news_clf.predict_proba([average_vec_img])\n",
    "categories=['ARTS', 'ARTS & CULTURE', 'BLACK VOICES', 'BUSINESS', 'COLLEGE',\n",
    "       'COMEDY', 'CRIME', 'CULTURE & ARTS', 'DIVORCE', 'EDUCATION',\n",
    "       'ENTERTAINMENT', 'ENVIRONMENT', 'FIFTY', 'FOOD & DRINK',\n",
    "       'GOOD NEWS', 'GREEN', 'HEALTHY LIVING', 'HOME & LIVING', 'IMPACT',\n",
    "       'LATINO VOICES', 'MEDIA', 'MONEY', 'PARENTING', 'PARENTS',\n",
    "       'POLITICS', 'QUEER VOICES', 'RELIGION', 'SCIENCE', 'SPORTS',\n",
    "       'STYLE', 'STYLE & BEAUTY', 'TASTE', 'TECH', 'TRAVEL', 'WEDDINGS',\n",
    "       'WEIRD NEWS', 'WELLNESS', 'WOMEN', 'WORLD NEWS', 'WORLDPOST']\n",
    "\n",
    "res=pd.DataFrame(columns=['Categories', 'Confidence'],index=range(40))\n",
    "pd.options.display.float_format = '{:.2f}%'.format\n",
    "res['Categories']=categories\n",
    "res['Confidence']=confidence_doc[0,:]*100\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLITICS'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_doc=news_clf.predict([average_vec_doc])\n",
    "prediction_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BUSINESS'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_img=news_clf.predict([average_vec_img])\n",
    "prediction_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01283173, 0.01781155, 0.01262159, 0.10912828, 0.00362053,\n",
       "        0.01758421, 0.0056115 , 0.0115328 , 0.0007806 , 0.00418123,\n",
       "        0.01735995, 0.01555056, 0.00218295, 0.01198729, 0.01262461,\n",
       "        0.01114563, 0.02460078, 0.01629208, 0.02335077, 0.00196849,\n",
       "        0.01261346, 0.05506082, 0.01484125, 0.00227819, 0.14140447,\n",
       "        0.00317981, 0.0106992 , 0.01470305, 0.00994401, 0.00325948,\n",
       "        0.04609305, 0.00396541, 0.02467936, 0.05409702, 0.01062906,\n",
       "        0.01044955, 0.11851814, 0.00403936, 0.04280277, 0.08397541]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf=confidence_doc*0.75+confidence_img*0.25\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLITICS'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[np.argmax(confidence_doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00937816, 0.00552076, 0.01334466, 0.07164088, 0.00455365,\n",
       "        0.01613356, 0.00497557, 0.01073036, 0.00084591, 0.00404534,\n",
       "        0.019876  , 0.01879543, 0.00211127, 0.0144813 , 0.00099326,\n",
       "        0.01361237, 0.03230748, 0.00936676, 0.02504588, 0.00215045,\n",
       "        0.01421844, 0.00985106, 0.01667769, 0.00141867, 0.16797334,\n",
       "        0.00388167, 0.01306042, 0.01916118, 0.01310555, 0.00330953,\n",
       "        0.05286928, 0.00496727, 0.02664242, 0.04223118, 0.00207595,\n",
       "        0.00422588, 0.1567152 , 0.00377317, 0.05540889, 0.10852415]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
